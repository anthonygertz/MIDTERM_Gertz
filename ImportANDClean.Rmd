```{r}
library(tidyverse)
library(dplyr)
library(fs)

options(scipen=999)
```



```{r}
#Initial test code just to make sure everything was working
#NOAA_Raw1950 <- read_csv("NOAA_Raw/StormEvents_details-ftp_v1.0_d1950_c20170120.csv")

#Reads in multiple subsequent csv files and combines them into a single dataframe
#Also does so by the list of chosen columns
files <- setwd("D:/NSS/MIDTERM_Gertz/NOAA_Raw")
files = list.files(pattern = "*.csv")
noaa_raw = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)[ ,        c('EVENT_ID', 'STATE', 'YEAR', 
      'MONTH_NAME', 'EVENT_TYPE', 'INJURIES_DIRECT',
      'DEATHS_DIRECT', 'DAMAGE_PROPERTY', 'BEGIN_LOCATION',
      'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON',
      'END_LAT', 'END_LON', 'CZ_NAME', 'STATE_FIPS', 'CZ_FIPS',
      'BEGIN_YEARMONTH')]
                                 ))
```



```{r}
#Creates a list of states for filtering
state_filter = c('ARKANSAS', 'TENNESSEE', 'ALABAMA', 'MISSISSIPPI', 
                    'GEORGIA', 'SOUTH CAROLINA', 'NORTH CAROLINA', 'KENTUCKY',
                 'WEST VIRGINIA')

#Filters the DF by the state_filter created above and only 2 disaster types
#Also renames columns from all caps to lower case, because
noaa_select <- noaa_raw %>%
  filter(EVENT_TYPE == 'Flood' | EVENT_TYPE == 'Flash Flood', STATE %in% state_filter) %>%
  rename(event_id = EVENT_ID, State = STATE, Year = YEAR, Month = MONTH_NAME, 
         Injuries = INJURIES_DIRECT, Deaths = DEATHS_DIRECT, damage = DAMAGE_PROPERTY, 
         begin_loc = BEGIN_LOCATION, end_loc = END_LOCATION, begin_lat = BEGIN_LAT, 
         begin_lon = BEGIN_LON, end_lat = END_LAT, end_lon = END_LON, County = CZ_NAME, 
         Event = EVENT_TYPE, state_fips = STATE_FIPS, county_fips = CZ_FIPS, date_order = BEGIN_YEARMONTH)

#Converts columns of all upper case values to only first letter capitals
noaa_select <- noaa_select %>%
  mutate(State = str_to_title(State), 
         County = str_to_title(County),
         begin_loc = str_to_title(begin_loc),
         end_loc = str_to_title(end_loc))

#Initial Test Code for the str_to_title function used for testing
#NOAA_Select$state <- str_to_title(NOAA_Select$state)
#NOAA_Select$county <- str_to_title(NOAA_Select$county) 
```



```{r}
#Creates two columns and places only the numerical portion from the damage column into damage_num

noaa_select <- noaa_select %>%
  separate(damage, c('damage_num', 'damage_mod'),
           '\\w$',
           remove = FALSE, convert = TRUE)

#Uses the 2nd column created above and reg extracts the units value 

noaa_select$damage_mod <- noaa_select$damage %>%
  str_extract('\\w$')
```

```{r}
#Filters out NA values and converts damage values to equal units based on damage_mod column
noaa_select <- noaa_select %>%
  filter(damage_mod == 'M' | damage_mod == 'K' & damage_num > 0) %>%
  mutate(Damage_Nominal = if_else(damage_mod == 'M',
                             1000000 * damage_num,
                             1000 * damage_num))
```


```{r}
#Loads in file with consumer price index from 1996 to 2020 adjusted for 1996 dollars and creates an adjusted column using 2020 CPI dollars as the new base

cpi <- read_csv("cpi/CPI1996_to_2019.csv") %>%
          mutate(cpi_adj = 161.75/CPI)

#Creates a new data frame that merges the CPI data by year and creates a new column that shows damage values by 2020 CPI dollars and fills empty values in the begin_loc column with 'Countywide'

floods <- merge(noaa_select, cpi, 
                by.x = 'Year', by.y = 'Year', 
                all.x = TRUE, all.y = FALSE) %>%
          mutate(Damage_CPIAdj = Damage_Nominal * cpi_adj) %>%
          mutate(begin_loc = if_else(begin_loc == '', 'Countywide', begin_loc)) %>%
          relocate(State, County, Year, Month, Event, Damage_Nominal, Damage_CPIAdj, CPI, Injuries, Deaths)
```


```{r}
#Imports two csv files containing census population data
census_old <- read_csv("pop/1996-1999.csv")
census_new <- read_csv("pop/2000-2019.csv")
```


```{r}
#Creates a list of state fips codes for extraction from the census data, similar to the state filter I used previously in this notebook with the NOAA/NWS data. 
fips_filter = c(1, 5, 13, 21, 28, 37, 45, 47, 54)

#The U.S. Census Bureau in all of their infinite wisdom has decided to continue publishing their old datasets in a format that varies 'widely' (hahaha, get it? it's a pun...*groan*) from their data sets post 1999. The code below pivots their older data so it can be joined with their new data. God forbid someone on the federal end does this data manipulation themselves, one time, instead of having what I can only assume is thousands of individuals doing so. 
census_full <- census_old %>%
  pivot_wider(names_from = 'Year',
              values_from = 'Pop') %>%
  filter(state_fips %in% fips_filter) %>%
  rename(pop1996 = `1996`, pop1997 = `1997`, pop1998 = `1998`, pop1999 = `1999`) %>%
  #rename(`2020` = pop2020, `2019` = pop2019, `2018` = pop2018, `2017` = pop2017, `2016` = pop2016, 
  #       `2015` = pop2015, `2014` = pop2014, `2013` = pop2013, `2012` = pop2012, `2011` = pop2011) %>%
  merge(census_new, by.x = c('state_fips', 'county_fips'), 
                    by.y = c('state_fips', 'county_fips'))
```


```{r}
#Placeholder for adding additional code



```


```{r}
#Creates a new data directory in my working directory
data <- dir_create('resiliency/data')

#Writes both necessary csv files to the working directory
write.csv(census_full, 'resiliency/data/census_full.csv', row.names = FALSE)
write.csv(floods, 'resiliency/data/floods.csv', row.names = FALSE)
```




